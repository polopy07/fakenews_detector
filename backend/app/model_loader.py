import html
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# ëª¨ë¸ ê²½ë¡œ ì„¤ì •
model_path = "C:/Users/sasha/OneDrive/Desktop/best_article_model"
tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)
model = AutoModelForSequenceClassification.from_pretrained(model_path, local_files_only=True)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval()

# ê°€ì§œë‰´ìŠ¤ ê´€ë ¨ ìœ„í—˜ í‚¤ì›Œë“œ
fake_keywords = [
    "ìŒëª¨ë¡ ", "ì™¸ê³„ì¸", "ì¢€ë¹„", "ë°±ì‹  ì‚¬ë§", "ê¸°ì§€ ê±´ì„¤", "ì •ë¶€ê°€ ìˆ¨ê²¼ë‹¤",
    "ì¡°ì‘ëœ ìë£Œ", "ë¬´ì¡°ê±´ ì£½ëŠ”ë‹¤", "ê·¹ë¹„ ë¬¸ì„œ", "ì„¸ê³„ì •ë¶€", "DNA ë³€í˜•",
    "5G ê°ì—¼", "ë¶ˆë¡œì¥ìƒ", "ë¬¼ í•œ ë°©ìš¸ë¡œ ì•” ì¹˜ë£Œ", "ë¯¸êµ­ì´ ì§€ì§„ ìœ ë°œ"
]

max_rule_score = len(fake_keywords)  # ì •ê·œí™”ì— ì‚¬ìš©

def rule_based_score(text):
    return sum(1 for kw in fake_keywords if kw in text)

def predict_fake_news(text):
    # í…ìŠ¤íŠ¸ ì •ë¦¬
    try:
        clean_text = html.unescape(text).replace("\r", " ").replace("\n", " ").strip()
    except Exception as e:
        print(f"[ERROR] í…ìŠ¤íŠ¸ ì •ë¦¬ ì‹¤íŒ¨: {e}")
        clean_text = text

    # Rule-based ì ìˆ˜ ê³„ì‚°
    rule_score = rule_based_score(clean_text)
    rule_score_norm = rule_score / max_rule_score  # 0~1ë¡œ ì •ê·œí™”

    # ëª¨ë¸ ì˜ˆì¸¡
    inputs = tokenizer(clean_text, return_tensors="pt", truncation=True, padding=True, max_length=512)
    inputs = {k: v.to(device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.softmax(outputs.logits, dim=1)
        real_prob = float(probs[0][0])
        fake_prob = float(probs[0][1])

    # ì•™ìƒë¸” ì ìˆ˜ ê³„ì‚°
    final_score = 0.7 * fake_prob + 0.3 * rule_score_norm
    label = 1 if final_score >= 0.5 else 0

    # ê²°ê³¼ ë©”ì‹œì§€
    if label == 1 and rule_score >= 1:
        result = "ğŸ”´ ê°€ì§œ ë‰´ìŠ¤ë¡œ íŒë‹¨ë¨ (ë”¥ëŸ¬ë‹ + í‚¤ì›Œë“œ ì¼ì¹˜)"
    elif label == 1:
        result = "ğŸ”´ ê°€ì§œ ë‰´ìŠ¤ë¡œ íŒë‹¨ë¨ (í™•ë¥  ê¸°ë°˜)"
    elif final_score >= 0.4:
        result = "âš ï¸ íŒë‹¨ ìœ ë³´"
    else:
        result = "ğŸŸ¢ ì§„ì§œ ë‰´ìŠ¤ë¡œ íŒë‹¨ë¨"

    print(f"[DEBUG] Softmax: {probs.tolist()} | Rule score: {rule_score} | Hybrid score: {final_score:.4f}")

    return {
        "label": label,
        "confidence": round(final_score, 4),
        "result": result,
        "probabilities": {
            "real": round(real_prob, 4),
            "fake": round(fake_prob, 4)
        },
        "rule_score": rule_score
    }
